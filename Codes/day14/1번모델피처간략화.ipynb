{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# 1ï¸âƒ£ ë‹¨ê³„: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
    "# ===================================================================\n",
    "!pip install xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# 2ï¸âƒ£ ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° ì„¤ì •\n",
    "# ===================================================================\n",
    "# âš ï¸ ì¤‘ìš”: ì•„ë˜ 'TARGET_COLUMN' ë³€ìˆ˜ ê°’ì„ ì‹¤ì œ íƒ€ê²Ÿ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”!\n",
    "# ì˜ˆ: TARGET_COLUMN = 'ë¶€ë„'\n",
    "TARGET_COLUMN = 'ì—¬ê¸°ì—_íƒ€ê²Ÿë³€ìˆ˜_ì»¬ëŸ¼ì´ë¦„ì„_ì…ë ¥í•˜ì„¸ìš”'\n",
    "\n",
    "file_path = '/content/final_ë¶€ë™ì‚°.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"âœ… '{file_path}' íŒŒì¼ ë¡œë“œ ì„±ê³µ!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: '{file_path}' ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
    "    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë” ì´ìƒ ì§„í–‰í•˜ì§€ ì•ŠìŒ\n",
    "    exit()\n",
    "\n",
    "# ì´ˆê¸° 20ê°œ í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ (íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ì´ ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ë˜ì§€ ì•Šì•„ì•¼ í•¨)\n",
    "initial_features = [\n",
    "    'ì—°ì²´ê³¼ëª©ìˆ˜_3ê°œì›”ìœ ì§€', 'ì—°ì²´ê¸°ê´€ìˆ˜_ì „ì²´', 'ìµœì¥ì—°ì²´ì¼ìˆ˜_3ê°œì›”',\n",
    "    'ìµœì¥ì—°ì²´ì¼ìˆ˜_6ê°œì›”', 'ìµœì¥ì—°ì²´ì¼ìˆ˜_1ë…„', 'ìµœì¥ì—°ì²´ì¼ìˆ˜_3ë…„', 'ì—°ì²´ê²½í—˜',\n",
    "    'ìœ ë™ìì‚°', 'ë¹„ìœ ë™ìì‚°', 'ìì‚°ì´ê³„', 'ìœ ë™ë¶€ì±„', 'ë¹„ìœ ë™ë¶€ì±„',\n",
    "    'ë¶€ì±„ì´ê³„', 'ë§¤ì¶œì•¡', 'ë§¤ì¶œì´ì´ìµ', 'ì˜ì—…ì†ìµ', 'ë‹¹ê¸°ìˆœì´ìµ', 'ì˜ì—…í™œë™í˜„ê¸ˆíë¦„',\n",
    "    'ì¬ë¬´ë¹„ìœ¨_ë¶€ì±„ë¹„ìœ¨', 'ì¬ë¬´ë¹„ìœ¨_ìœ ë™ë¹„ìœ¨'\n",
    "]\n",
    "\n",
    "# íƒ€ê²Ÿ ë³€ìˆ˜ì™€ í”¼ì²˜ ë¶„ë¦¬\n",
    "if TARGET_COLUMN not in df.columns:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: ë°ì´í„°ì— '{TARGET_COLUMN}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼ëª…ì„ í™•ì¸í•˜ê³  ìˆ˜ì •í•´ì£¼ì„¸ìš”.\")\n",
    "    print(\"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼:\", df.columns.tolist())\n",
    "    exit()\n",
    "\n",
    "X = df[initial_features]\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# 3ï¸âƒ£ ë‹¨ê³„: íŒŒì´í”„ë¼ì¸ ë° í›„ì§„ ì œê±°ë²• í•¨ìˆ˜ ì •ì˜\n",
    "# ===================================================================\n",
    "class BankruptcyPredictionPipeline:\n",
    "    \"\"\"ê¸°ì—…ë¶€ë„ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.feature_names = None\n",
    "        self.is_fitted = False\n",
    "        self.selected_features = []\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        self.feature_names = self.selected_features\n",
    "        X_selected = X[self.feature_names]\n",
    "        estimators = [\n",
    "            ('xgb', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')),\n",
    "            ('rf', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "        ]\n",
    "        self.model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(class_weight='balanced'), cv=3, n_jobs=-1)\n",
    "        self.model.fit(X_selected, y)\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        X_selected = X[self.feature_names].copy()\n",
    "        return self.model.predict(X_selected)\n",
    "\n",
    "def run_backward_elimination(X_train, y_train, X_test, y_test, initial_features, recall_threshold=0.79):\n",
    "    \"\"\"í›„ì§„ ì œê±°ë²•ì„ ìˆ˜í–‰í•˜ì—¬ ìµœì ì˜ í”¼ì²˜ ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤.\"\"\"\n",
    "    current_features = initial_features.copy()\n",
    "    print(f\"ğŸš€ í›„ì§„ ì œê±°ë²• ì‹œì‘... (Recall ìœ ì§€ ì¡°ê±´: {recall_threshold} ì´ìƒ)\")\n",
    "    print(\"-\" * 60)\n",
    "    step = 1\n",
    "    while len(current_features) > 1:\n",
    "        recall_per_feature = []\n",
    "        for feature_to_remove in current_features:\n",
    "            temp_features = [f for f in current_features if f != feature_to_remove]\n",
    "            pipeline = BankruptcyPredictionPipeline()\n",
    "            pipeline.selected_features = temp_features\n",
    "            with contextlib.redirect_stdout(io.StringIO()):\n",
    "                pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "            recall_per_feature.append({'feature': feature_to_remove, 'recall': recall})\n",
    "        \n",
    "        best_candidate = max(recall_per_feature, key=lambda x: x['recall'])\n",
    "        \n",
    "        if best_candidate['recall'] >= recall_threshold:\n",
    "            feature_to_eliminate = best_candidate['feature']\n",
    "            recall_at_elimination = best_candidate['recall']\n",
    "            print(f\"â¡ï¸ ë‹¨ê³„ {step}: '{feature_to_eliminate}' ì œê±° (ì œê±° í›„ Recall: {recall_at_elimination:.4f})\")\n",
    "            current_features.remove(feature_to_eliminate)\n",
    "            step += 1\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸ ì¤‘ë‹¨: '{best_candidate['feature']}' ì œê±° ì‹œ Recall({best_candidate['recall']:.4f})ì´ ì„ê³„ê°’ ë¯¸ë§Œ.\")\n",
    "            break\n",
    "            \n",
    "    print(\"-\" * 60)\n",
    "    print(\"âœ… í›„ì§„ ì œê±°ë²• ì™„ë£Œ!\")\n",
    "    return current_features\n",
    "\n",
    "# ===================================================================\n",
    "# 4ï¸âƒ£ ë‹¨ê³„: ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥\n",
    "# ===================================================================\n",
    "final_features = run_backward_elimination(X_train, y_test, X_test, y_test, initial_features)\n",
    "\n",
    "print(\"\\n\\n--- ìµœì¢… ê²°ê³¼ ---\")\n",
    "print(f\"\\nğŸ“Š ìµœì¢… ì„ íƒëœ í”¼ì²˜ ê°œìˆ˜: {len(final_features)}\")\n",
    "print(\"\\nğŸ“‹ ìµœì¢… í”¼ì²˜ ëª©ë¡:\")\n",
    "for feature in final_features:\n",
    "    print(f\"  - {feature}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
